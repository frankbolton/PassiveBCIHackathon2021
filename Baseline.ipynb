{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80b2ea2c",
   "metadata": {},
   "source": [
    "## 1 Hackathon baseline\n",
    "We provide here a simple pipeline to read the data, train a Tangent Space Classifier and try naive\n",
    "transfer between sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "015e60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "from mne.externals.pymatreader import read_mat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from glob import glob\n",
    "import pyriemann\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b15ac2e",
   "metadata": {},
   "source": [
    "Here set the data_path to corresponding path on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5c931e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:\\\\Users\\\\frank\\\\code\\\\NeuroErgonomics_Hackathon_2021'\n",
    "#'/home/dcas/l.darmet/data/contest/comeptition_done'\n",
    "n_subs = 4\n",
    "n_sessions = 2\n",
    "diff = ['MATBeasy', 'MATBmed', 'MATBdiff']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f4b9c",
   "metadata": {},
   "source": [
    "Read channels names and position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e285479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ch_names        x       y       z\n",
      "0       Fp1 -29.4370  83.917  -6.990\n",
      "1        Fz   0.3122  58.512  66.462\n",
      "2        F3 -50.2440  53.111  42.192\n",
      "3        F7 -70.2630  42.474 -11.420\n",
      "4       FT9 -84.0760  14.567 -50.429\n"
     ]
    }
   ],
   "source": [
    "electrodes = pd.read_csv(data_path + '/Electrodes/chan_locs_standard',header=None, sep ='\\t', names=['ch_names','x','y','z'])\n",
    "print(electrodes.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d369f51b",
   "metadata": {},
   "source": [
    "Covariance estimation For robust covariance estimation, we take advantage of shrinkage. Here\n",
    "the [Oracle Approximating Shrinkage](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.OAS.html) (OAS) is used. #### Classifier We use a simple Logistic\n",
    "Regression (with a non-optimized L2 penalty) on [Tangent Space Features](https://hal.archives-ouvertes.fr/hal-00681328/document), extracted with [Pyriemann\n",
    "toolbox](https://pyriemann.readthedocs.io/en/latest/). #### Channel selection A manual and naive EEG channel selection is performed\n",
    "to use 13 electrodes, mostly frontal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c53af3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1/10.)\n",
    "clf = make_pipeline(pyriemann.estimation.Covariances(estimator='oas'),\n",
    "    pyriemann.classification.TSclassifier(clf=lr))\n",
    "\n",
    "\n",
    "ch_slice = ['F7', 'F5', 'F3', 'F1', 'F2', 'F4', 'F6', 'AF3', 'AFz', 'AF4','FP1', 'FP2', 'FPz']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b387cd",
   "metadata": {},
   "source": [
    "## 1.1 Single subject epochs classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18e72982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject P01 and session 1: mean accuracy of 0.78 with a standard deviation of 0.03\n",
      "Subject P01 and session 2: mean accuracy of 0.74 with a standard deviation of 0.06\n",
      "Subject P02 and session 1: mean accuracy of 0.74 with a standard deviation of 0.04\n",
      "Subject P02 and session 2: mean accuracy of 0.83 with a standard deviation of 0.08\n",
      "Subject P03 and session 1: mean accuracy of 0.67 with a standard deviation of 0.05\n",
      "Subject P03 and session 2: mean accuracy of 0.63 with a standard deviation of 0.1\n",
      "Subject P04 and session 1: mean accuracy of 0.73 with a standard deviation of 0.03\n",
      "Subject P04 and session 2: mean accuracy of 0.78 with a standard deviation of 0.06\n"
     ]
    }
   ],
   "source": [
    "for sub_n, session_n in itertools.product(range(n_subs), range(n_sessions)):\n",
    "    epochs_data = []\n",
    "    labels = []\n",
    "    for lab_idx, level in enumerate(diff):\n",
    "        sub = 'P{0:02d}'.format(sub_n+1)\n",
    "        sess = f'S{session_n+1}'\n",
    "        path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/alldata_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}_{level}.set'\n",
    "        # Read the epoched data with MNE\n",
    "        epochs = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "        # You could add some pre-processing here with MNE\n",
    "        # We will just select some channels (mostly frontal ones)\n",
    "        epochs = epochs.drop_channels(list(set(epochs.ch_names) -set(ch_slice)))\n",
    "\n",
    "        # Get the data and concatenante with others MATB levels\n",
    "        tmp = epochs.get_data()\n",
    "        epochs_data.extend(tmp)\n",
    "        labels.extend([lab_idx]*len(tmp))\n",
    "    \n",
    "    epochs_data = np.array(epochs_data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Compute classification accuracy with 5-folds cross validation\n",
    "    acc = cross_val_score(clf, X=epochs_data, y=labels, cv=5)\n",
    "#     print(acc)\n",
    "    print(f'Subject {sub} and session {session_n+1}: mean accuracy of {round(np.mean(acc), 2)} with a standard deviation of {round(np.std(acc), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2c636d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "<EpochsEEGLAB |  149 events (all good), 0 - 1.996 sec, baseline off, ~5.7 MB, data loaded,\n",
      " 'MATBdiff': 149>\n",
      "(149, 10, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(447, 10, 500)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = epochs.get_data()\n",
    "print(len(tmp))\n",
    "print(epochs)\n",
    "print(epochs.get_data().shape)\n",
    "epochs_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3da57",
   "metadata": {},
   "source": [
    "## 1.2 Transfer from session 1 to session 2 for P01\n",
    "For subject P01, a model is trained on session 1 and directly used for epochs of session 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00dd439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_n = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48c09b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('covariances', Covariances(estimator='oas')),\n",
       "                ('tsclassifier', TSclassifier(clf=LogisticRegression(C=0.1)))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_n = 0\n",
    "epochs_data = []\n",
    "labels = []\n",
    "for lab_idx, level in enumerate(diff):\n",
    "    sub = 'P{0:02d}'.format(sub_n+1)\n",
    "    sess = f'S{session_n+1}'\n",
    "    path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/alldata_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}_{level}.set'\n",
    "    # Read the epoched data with MNE\n",
    "    epochs = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "    # You could add some pre-processing here with MNE\n",
    "    # We will just select some channels (mostly frontal ones)\n",
    "    epochs = epochs.drop_channels(list(set(epochs.ch_names) - set(ch_slice)))\n",
    "\n",
    "    # Get the data and concatenante with others MATB levels\n",
    "    tmp = epochs.get_data()\n",
    "    epochs_data.extend(tmp)\n",
    "    labels.extend([lab_idx]*len(tmp))\n",
    "\n",
    "epochs_data = np.array(epochs_data)\n",
    "labels = np.array(labels)\n",
    "# Train the model on all epochs from session 1\n",
    "clf.fit(epochs_data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9eb41ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject P01 and transfer from session 1 to 2: mean accuracy of 0.33.\n"
     ]
    }
   ],
   "source": [
    "session_n = 1\n",
    "epochs_data = []\n",
    "labels = []\n",
    "for lab_idx, level in enumerate(diff):\n",
    "    sub = 'P{0:02d}'.format(sub_n+1)\n",
    "    sess = f'S{session_n+1}'\n",
    "    path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/alldata_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}_{level}.set'\n",
    "    # Read the epoched data with MNE\n",
    "    tmp = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "    # You could add some pre-processing here with MNE\n",
    "    # We will just select some channels (mostly frontal ones)\n",
    "    epochs = epochs.drop_channels(list(set(epochs.ch_names) - set(ch_slice)))\n",
    "    \n",
    "    # Get the data and concatenante with others MATB levels\n",
    "    tmp = epochs.get_data()\n",
    "    epochs_data.extend(tmp)\n",
    "    labels.extend([lab_idx]*len(tmp))\n",
    "\n",
    "epochs_data = np.array(epochs_data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Use trained model to predict for all epochs of session 2 and compute accuracy\n",
    "y_pred = clf.predict(epochs_data)\n",
    "acc = accuracy_score(labels, y_pred)\n",
    "print(f'Subject {sub} and transfer from session 1 to 2: mean accuracy of {round(acc, 2)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a551760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochID  prediction\n",
       "0        0           2\n",
       "1        1           2\n",
       "2        2           2\n",
       "3        3           2\n",
       "4        4           2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'epochID':np.arange(len(y_pred)), 'prediction' : y_pred})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4d0277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f375a0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_predd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-90e137ae48cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_predd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_predd' is not defined"
     ]
    }
   ],
   "source": [
    "y_predd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "454a6619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.43385100e-06, -3.25384760e-06, -3.09842110e-06, ...,\n",
       "        -8.03505719e-07,  3.11282337e-07,  6.09637380e-07],\n",
       "       [-4.68323421e-06, -2.03526258e-06,  9.80643332e-07, ...,\n",
       "         3.26994777e-06,  3.05282140e-06,  2.02247977e-06],\n",
       "       [-4.08609438e-06, -2.65402174e-06, -7.46625483e-07, ...,\n",
       "        -3.97810507e-06, -2.48682380e-06, -1.17737222e-06],\n",
       "       ...,\n",
       "       [-3.58012199e-06, -2.18071938e-06, -4.29864407e-07, ...,\n",
       "        -3.92317629e-06, -2.15039706e-06, -8.55384648e-07],\n",
       "       [-4.96033669e-06, -3.40122247e-06, -3.70908201e-07, ...,\n",
       "        -6.67918158e-06, -4.01019335e-06, -1.40368879e-06],\n",
       "       [-3.30757880e-06, -2.32430816e-06, -8.93423736e-07, ...,\n",
       "        -3.89818478e-06, -2.34262514e-06, -1.10610080e-06]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce37aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d030c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
