{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf81c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn.utils import shuffle\n",
    "# from sktime.classification.compose import ColumnEnsembleClassifier\n",
    "# from sktime.classification.dictionary_based import BOSSEnsemble\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "# from sktime.classification.shapelet_based import MrSEQLClassifier\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from sktime.transformations.panel.tsfresh import TSFreshFeatureExtractor\n",
    "\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "from mne.externals.pymatreader import read_mat\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2baf3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:\\\\Users\\\\frank\\\\code\\\\NeuroErgonomics_Hackathon_2021'\n",
    "#'/home/dcas/l.darmet/data/contest/comeptition_done'\n",
    "n_subs = 2\n",
    "diff = ['MATBeasy', 'MATBmed', 'MATBdiff']\n",
    "\n",
    "ch_slice = ['F7', 'F5', 'F3', 'F1', 'F2', 'F4', 'F6', 'AF3', 'AFz', 'AF4','FP1', 'FP2', 'FPz']\n",
    "# ch_slice = ['FP1']\n",
    "\n",
    "narrow_feature_space = True\n",
    "n_estimators = 20 \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 50/50 [03:46<00:00,  4.54s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 50/50 [04:28<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44742729306487694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Feature Extraction:   0%|                                                                       | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "accuracies = list()\n",
    "# for sub_n, session_n in itertools.product(range(n_subs), range(n_sessions)):\n",
    "for sub_n in range(n_subs):\n",
    "    session_n = 0\n",
    "    epochs_data = []\n",
    "    labels = []\n",
    "    for lab_idx, level in enumerate(diff):\n",
    "        sub = 'P{0:02d}'.format(sub_n+1)\n",
    "        sess = f'S{session_n+1}'\n",
    "        path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/alldata_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}_{level}.set'\n",
    "        # Read the epoched data with MNE\n",
    "        epochs = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "        # You could add some pre-processing here with MNE\n",
    "        # We will just select some channels (mostly frontal ones)\n",
    "        if (narrow_feature_space):\n",
    "            epochs = epochs.drop_channels(list(set(epochs.ch_names) -set(ch_slice)))\n",
    "\n",
    "        # Get the data and concatenante with others MATB levels\n",
    "        tmp = epochs.get_data()\n",
    "        epochs_data.extend(tmp)\n",
    "        labels.extend([lab_idx]*len(tmp))\n",
    "    \n",
    "        X = np.array(epochs_data)\n",
    "    labels = np.array(labels)\n",
    "    y = labels\n",
    "    x_names = [f'dim_{x}' for x in range(X.shape[1])]    \n",
    "    X_df = pd.DataFrame(columns = x_names)\n",
    "\n",
    "    sample =  0 \n",
    "    for sample in range(X.shape[0]):\n",
    "        data = X[sample,:,:]\n",
    "        list_of_series = []\n",
    "        for xx in range(X.shape[1]):\n",
    "            list_of_series.append(X[sample,xx,:])\n",
    "\n",
    "        X_df = X_df.append(pd.DataFrame([list_of_series], columns = x_names))\n",
    "\n",
    "    X_df.reset_index(drop = True)\n",
    "\n",
    "\n",
    "    session_n = 1\n",
    "    epochs_data = []\n",
    "    labels = []\n",
    "    for lab_idx, level in enumerate(diff):\n",
    "        sub = 'P{0:02d}'.format(sub_n+1)\n",
    "        sess = f'S{session_n+1}'\n",
    "        path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/alldata_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}_{level}.set'\n",
    "        # Read the epoched data with MNE\n",
    "        epochs = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "        # You could add some pre-processing here with MNE\n",
    "        # We will just select some channels (mostly frontal ones)\n",
    "        if (narrow_feature_space):\n",
    "            epochs = epochs.drop_channels(list(set(epochs.ch_names) -set(ch_slice)))\n",
    "\n",
    "        # Get the data and concatenante with others MATB levels\n",
    "        tmp = epochs.get_data()\n",
    "        epochs_data.extend(tmp)\n",
    "        labels.extend([lab_idx]*len(tmp))\n",
    "    \n",
    "        X_s2 = np.array(epochs_data)\n",
    "    labels = np.array(labels)\n",
    "    y_s2 = labels\n",
    "\n",
    "\n",
    "    Xs2_df = pd.DataFrame(columns = x_names)\n",
    "\n",
    "    sample =  0 \n",
    "    for sample in range(X_s2.shape[0]):\n",
    "        data = X_s2[sample,:,:]\n",
    "        list_of_series = []\n",
    "        for xx in range(X_s2.shape[1]):\n",
    "            list_of_series.append(X_s2[sample,xx,:])\n",
    "\n",
    "        Xs2_df = Xs2_df.append(pd.DataFrame([list_of_series], columns = x_names))\n",
    "\n",
    "    Xs2_df.reset_index(drop = True)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = X_df, Xs2_df, y, y_s2\n",
    "    \n",
    "    X_test, y_test = shuffle(X_test, y_test, random_state=0)\n",
    "    \n",
    "#This model gave the best perfromance over the full group\n",
    "    steps = [\n",
    "        (\"concatenate\", ColumnConcatenator()),\n",
    "        (\"classify\", TimeSeriesForestClassifier(n_estimators=data_params['n_estimators'], random_state=0, n_jobs=-1)),\n",
    "        ]\n",
    "    clf = Pipeline(steps)\n",
    "#This model gave the best performance over 4 participants- never ran to completion\n",
    "#     clf = make_pipeline(\n",
    "#         ColumnConcatenator(), TSFreshFeatureExtractor(n_jobs=-1, show_warnings=False), RandomForestClassifier(random_state=0)\n",
    "#         )\n",
    "\n",
    "    ###____\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    accuracies.append(acc)\n",
    "    print(acc)\n",
    "    \n",
    "print(f'the average accuracy is {np.mean(accuracies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099607a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d617d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
