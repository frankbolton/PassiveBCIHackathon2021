{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf81c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from sktime.transformations.panel.tsfresh import TSFreshFeatureExtractor\n",
    "\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "from mne.externals.pymatreader import read_mat\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2baf3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/frank/Documents/PassiveBCIHackathon2021'#'C:\\\\Users\\\\frank\\\\code\\\\NeuroErgonomics_Hackathon_2021'\n",
    "\n",
    "# data_path = '/home/dcas/l.darmet/data/contest/comeptition_done'\n",
    "n_subs = 2\n",
    "diff = ['MATBeasy', 'MATBmed', 'MATBdiff']\n",
    "\n",
    "ch_slice = ['F7', 'F5', 'F3', 'F1', 'F2', 'F4', 'F6', 'AF3', 'AFz', 'AF4','FP1', 'FP2', 'FPz']\n",
    "# ch_slice = ['FP1', 'FP2', 'FPz']\n",
    "\n",
    "\n",
    "n_estimators = 300 \n",
    "narrow_feature_space = False\n",
    "\n",
    "#_TEST\n",
    "n_estimators = 10 \n",
    "narrow_feature_space = True\n",
    "\n",
    "data_params =   {'n_estimators': n_estimators,\n",
    "                    'narrow_feature_space': narrow_feature_space,\n",
    "                }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d11fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = list()\n",
    "# # for sub_n, session_n in itertools.product(range(n_subs), range(n_sessions)):\n",
    "# for sub_n in range(n_subs):\n",
    "#     session_n = 0\n",
    "#     epochs_data = []\n",
    "#     labels = []\n",
    "#     for lab_idx, level in enumerate(diff):\n",
    "#         sub = 'P{0:02d}'.format(sub_n+1)\n",
    "#         sess = f'S{session_n+1}'\n",
    "#         path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/alldata_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}_{level}.set'\n",
    "#         # Read the epoched data with MNE\n",
    "#         epochs = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "#         # You could add some pre-processing here with MNE\n",
    "#         # We will just select some channels (mostly frontal ones)\n",
    "#         if (narrow_feature_space):\n",
    "#             epochs = epochs.drop_channels(list(set(epochs.ch_names) -set(ch_slice)))\n",
    "\n",
    "#         # Get the data and concatenante with others MATB levels\n",
    "#         tmp = epochs.get_data()\n",
    "#         epochs_data.extend(tmp)\n",
    "#         labels.extend([lab_idx]*len(tmp))\n",
    "    \n",
    "#         X = np.array(epochs_data)\n",
    "#     labels = np.array(labels)\n",
    "#     y = labels\n",
    "#     x_names = [f'dim_{x}' for x in range(X.shape[1])]    \n",
    "#     X_df = pd.DataFrame(columns = x_names)\n",
    "\n",
    "#     sample =  0 \n",
    "#     for sample in range(X.shape[0]):\n",
    "#         data = X[sample,:,:]\n",
    "#         list_of_series = []\n",
    "#         for xx in range(X.shape[1]):\n",
    "#             list_of_series.append(X[sample,xx,:])\n",
    "\n",
    "#         X_df = X_df.append(pd.DataFrame([list_of_series], columns = x_names))\n",
    "\n",
    "#     X_df.reset_index(drop = True)\n",
    "\n",
    "\n",
    "#     session_n = 1\n",
    "#     epochs_data = []\n",
    "#     labels = []\n",
    "#     for lab_idx, level in enumerate(diff):\n",
    "#         sub = 'P{0:02d}'.format(sub_n+1)\n",
    "#         sess = f'S{session_n+1}'\n",
    "#         path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/alldata_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}_{level}.set'\n",
    "#         # Read the epoched data with MNE\n",
    "#         epochs = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "#         # You could add some pre-processing here with MNE\n",
    "#         # We will just select some channels (mostly frontal ones)\n",
    "#         if (narrow_feature_space):\n",
    "#             epochs = epochs.drop_channels(list(set(epochs.ch_names) -set(ch_slice)))\n",
    "\n",
    "#         # Get the data and concatenante with others MATB levels\n",
    "#         tmp = epochs.get_data()\n",
    "#         epochs_data.extend(tmp)\n",
    "#         labels.extend([lab_idx]*len(tmp))\n",
    "    \n",
    "#         X_s2 = np.array(epochs_data)\n",
    "#     labels = np.array(labels)\n",
    "#     y_s2 = labels\n",
    "\n",
    "\n",
    "#     Xs2_df = pd.DataFrame(columns = x_names)\n",
    "\n",
    "#     sample =  0 \n",
    "#     for sample in range(X_s2.shape[0]):\n",
    "#         data = X_s2[sample,:,:]\n",
    "#         list_of_series = []\n",
    "#         for xx in range(X_s2.shape[1]):\n",
    "#             list_of_series.append(X_s2[sample,xx,:])\n",
    "\n",
    "#         Xs2_df = Xs2_df.append(pd.DataFrame([list_of_series], columns = x_names))\n",
    "\n",
    "#     Xs2_df.reset_index(drop = True)\n",
    "        \n",
    "#     X_train, X_test, y_train, y_test = X_df, Xs2_df, y, y_s2\n",
    "    \n",
    "#     X_test, y_test = shuffle(X_test, y_test, random_state=0)\n",
    "    \n",
    "# #This model gave the best perfromance over the full group\n",
    "# #     steps = [\n",
    "# #         (\"concatenate\", ColumnConcatenator()),\n",
    "# #         (\"classify\", TimeSeriesForestClassifier(n_estimators=data_params['n_estimators'], random_state=0, n_jobs=-1)),\n",
    "# #         ]\n",
    "# #     clf = Pipeline(steps)\n",
    "# #This model gave the best performance over 4 participants- never ran to completion\n",
    "#     clf = make_pipeline(\n",
    "#         TSFreshFeatureExtractor(n_jobs=-1, show_warnings=True), RandomForestClassifier(n_jobs=-1,random_state=0)\n",
    "# #         ColumnConcatenator(), TSFreshFeatureExtractor(n_jobs=-1, show_warnings=False), RandomForestClassifier(n_jobs=-1,random_state=0)\n",
    "        \n",
    "#         )\n",
    "\n",
    "#     ###____\n",
    "\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     acc = clf.score(X_test, y_test)\n",
    "#     accuracies.append(acc)\n",
    "#     print(acc)\n",
    "#     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") )\n",
    "# #     s = pickle.dumps(clf)\n",
    "    \n",
    "    \n",
    "    \n",
    "# print(f'the average accuracy is {np.mean(accuracies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8f2a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = make_pipeline(\n",
    "#         ColumnConcatenator(), TSFreshFeatureExtractor(n_jobs=-1, show_warnings=False), RandomForestClassifier(n_jobs=-1,random_state=0)      \n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d21079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - session 0\n",
      "447\n",
      "(447, 10, 500)\n",
      "0 - session 1\n",
      "894\n",
      "(894, 10, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:  19%|█▉        | 17/90 [01:55<02:45,  2.27s/it] "
     ]
    }
   ],
   "source": [
    "all_results = pd.DataFrame({'epochID':np.arange(447)})\n",
    "\n",
    "# sub_n = 1\n",
    "file_time = 'outputs/'+datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "for sub_n in range(n_subs):\n",
    "    # Train\n",
    "    print(f\"{sub_n} - session 0\")\n",
    "    session_n = 0\n",
    "    epochs_data = []\n",
    "    labels = []\n",
    "    for lab_idx, level in enumerate(diff):\n",
    "        sub = 'P{0:02d}'.format(sub_n+1)\n",
    "        sess = f'S{session_n+1}'\n",
    "        path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/alldata_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}_{level}.set'\n",
    "        # Read the epoched data with MNE\n",
    "        epochs = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "        # You could add some pre-processing here with MNE\n",
    "        # We will just select some channels (mostly frontal ones)\n",
    "        if (narrow_feature_space):\n",
    "            epochs = epochs.drop_channels(list(set(epochs.ch_names) - set(ch_slice)))\n",
    "\n",
    "        # Get the data and concatenante with others MATB levels\n",
    "        tmp = epochs.get_data()\n",
    "        epochs_data.extend(tmp)\n",
    "        labels.extend([lab_idx]*len(tmp))\n",
    "    print(len(labels))\n",
    "    print(np.array(epochs_data).shape)\n",
    "\n",
    "\n",
    "    print(f\"{sub_n} - session 1\")\n",
    "    session_n = 1\n",
    "    for lab_idx, level in enumerate(diff):\n",
    "        sub = 'P{0:02d}'.format(sub_n+1)\n",
    "        sess = f'S{session_n+1}'\n",
    "        path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/alldata_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}_{level}.set'\n",
    "        # Read the epoched data with MNE\n",
    "        epochs = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "        # You could add some pre-processing here with MNE\n",
    "        # We will just select some channels (mostly frontal ones)\n",
    "        if (narrow_feature_space):\n",
    "            epochs = epochs.drop_channels(list(set(epochs.ch_names) - set(ch_slice)))\n",
    "\n",
    "        # Get the data and concatenante with others MATB levels\n",
    "        tmp = epochs.get_data()\n",
    "        epochs_data.extend(tmp)\n",
    "        labels.extend([lab_idx]*len(tmp))\n",
    "    print(len(labels))\n",
    "\n",
    "    epochs_data = np.array(epochs_data)\n",
    "    print(epochs_data.shape)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Train the model on all epochs from session 1 and 2\n",
    "#     lr = LogisticRegression(C=1/10.)\n",
    "#     clf = make_pipeline(pyriemann.estimation.Covariances(estimator='oas'),\n",
    "#         pyriemann.classification.TSclassifier(clf=lr))\n",
    "    clf = make_pipeline(\n",
    "        ColumnConcatenator(), TSFreshFeatureExtractor(n_jobs=-1, show_warnings=False), RandomForestClassifier(n_jobs=-1,random_state=0)      \n",
    "        )\n",
    "    clf.fit(epochs_data, labels)\n",
    "\n",
    "    #Validate on Session 3\n",
    "    print(f\"{sub_n} - session 2\")\n",
    "    session_n = 2\n",
    "    epochs_data = []\n",
    "    # labels = []\n",
    "    # for lab_idx, level in enumerate(diff_submission):\n",
    "    sub = 'P{0:02d}'.format(sub_n+1)\n",
    "    sess = f'S{session_n+1}'\n",
    "    path = os.path.join(os.path.join(data_path, sub), sess) + f'/eeg/testset_sbj{str(sub_n+1).zfill(2)}_sess{session_n+1}.set'\n",
    "    # print(path)\n",
    "    # # Read the epoched data with MNE\n",
    "    epochs = mne.io.read_epochs_eeglab(path, verbose=False)\n",
    "    # You could add some pre-processing here with MNE\n",
    "    # We will just select some channels (mostly frontal ones)\n",
    "    if (narrow_feature_space):\n",
    "        epochs = epochs.drop_channels(list(set(epochs.ch_names) - set(ch_slice)))\n",
    "\n",
    "    # Get the data and concatenante with others MATB levels\n",
    "    tmp = epochs.get_data()\n",
    "    # print(type(tmp))\n",
    "    epochs_data.extend(tmp)\n",
    "    # labels.extend(len(tmp))\n",
    "\n",
    "    epochs_data = np.array(epochs_data)\n",
    "    print(epochs_data.shape)\n",
    "    # labels = np.array(labels)\n",
    "\n",
    "    # Use trained model to predict for all epochs of session 2 and compute accuracy\n",
    "    y_pred = clf.predict(epochs_data)\n",
    "    # print(y_pred)\n",
    "    print(len(y_pred))\n",
    "\n",
    "    submission = pd.DataFrame({'epochID':np.arange(len(y_pred)), f'prediction_sub{sub_n}' : y_pred})\n",
    "    submission.to_csv(f\"{file_time}_{sub_n}_submission.csv\",header=True,index=False)\n",
    "\n",
    "    filename = f\"{file_time}_{sub_n}_finalized_model.sav\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    all_results =  all_results.merge(submission,left_on='epochID', right_on='epochID')\n",
    "\n",
    "    \n",
    "all_results.to_csv(f\"{file_time}_allresults_submission.csv\",header=True,index=False)\n",
    "    # submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82766be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
